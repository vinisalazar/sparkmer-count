{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkConf\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "import pyspark.sql.types as T \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col, size\n",
    "from operator import add\n",
    "from os import path\n",
    "from functools import reduce\n",
    "from bio_spark.io.fasta_reader import FASTAReader, FASTAQReader\n",
    "import collections\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre este Notebook\n",
    "\n",
    "Este notebook será dividido em duas tarefas: contagem de *k*-mers em genomas bacterianos e clusterização hierárquica do uso de *k*-mers nesses genomas. Para essa análise, vamos montar um cluster local de Spark usando Docker Compose. Essa análise permite uma análise *de novo* de similaridade entre os genomas, ou seja, ela pode ser feita sem uma referência externa.\n",
    "\n",
    "O fluxo é composto dos seguintes passos:\n",
    "\n",
    "1. Leitura e parsing do arquivos fasta de entrada\n",
    "2. Cálculo dos *k*-mers a partir das sequências encontradas nos arquivos de entrada\n",
    "3. Uso do método de Elbow para encontrar clusters coesos.\n",
    "\n",
    "___\n",
    "\n",
    "## Cluster local\n",
    "\n",
    "Para fins de desenvolvimento, utilizamos imagens Docker para criar um cluster spark local. Esse cluster deve estar rodadndo para que o notebook funcione como esperado. Na raiz do projeto:\n",
    "\n",
    "```shell\n",
    "docker-compose up\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sConf = SparkConf(\"spark://localhost:7077\")\n",
    "sc = SparkContext(conf=sConf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Tdoso os arquivos de entrada serão tratados em único Dataframe\n",
    "\n",
    "```shell\n",
    "INPUT_DIR_PATH: caminho para o diretório com os arquivs .fna (FASTA)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = \"/Users/viniWS/Bio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to process : 171\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIR_PATH = Path(home, \"sparkAAI/data/genomes/synechococcus\")\n",
    "files_to_process = [str(f) for f in INPUT_DIR_PATH.iterdir()]\n",
    "print(\"Files to process :\", len(files_to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw file lines to process 4490766\n"
     ]
    }
   ],
   "source": [
    "fasta_plain_df = sc.textFile(','.join(files_to_process))\\\n",
    "            .map(lambda x: Row(row=x))\\\n",
    "            .zipWithIndex()\\\n",
    "            .toDF([\"row\",\"idx\"])\n",
    "\n",
    "print(\"raw file lines to process\", fasta_plain_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecionando o dataframe lido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                 row|idx|\n",
      "+--------------------+---+\n",
      "|[>QCWF01000001.1 ...|  0|\n",
      "|[TTTTTTTGTGTCTAGA...|  1|\n",
      "|[TCACCGCGTGATCAGG...|  2|\n",
      "|[AGATCCTGGTTTCACA...|  3|\n",
      "|[ACCGATTCATCGCCCA...|  4|\n",
      "|[AAAAGCCCGGTCACTG...|  5|\n",
      "|[AGCTGAATCCTTGCGG...|  6|\n",
      "|[AGAGGAACTCTTCGGC...|  7|\n",
      "|[TAGCCCTCGTCGACCA...|  8|\n",
      "|[TTCCTTGAGCATGATC...|  9|\n",
      "|[TCAGGAACTCTGGGCG...| 10|\n",
      "|[TCGCCGCCAGAGAACT...| 11|\n",
      "|[CAGTGTGTTCTTGAAG...| 12|\n",
      "|[ACACATCGGGGTGTGC...| 13|\n",
      "|[CCGCCTTCGTTGAAGC...| 14|\n",
      "|[GTCCAGGCGGATCATC...| 15|\n",
      "|[TTGGGCCGGAGAAGAT...| 16|\n",
      "|[ACCGCCTTGACGGCTT...| 17|\n",
      "|[CTCGGTGAGCTTCTGA...| 18|\n",
      "|[TCTCACTCACAGCAGC...| 19|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_plain_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse dos arquivos FASTA\n",
    "\n",
    "os arquivos [FASTA]([FASTA](https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=BlastHelp)), tem o seguinte formato:\n",
    "\n",
    "```\n",
    ">ID.CONTIG\n",
    "ATTC....\n",
    "GCG...\n",
    "CCG...\n",
    ">ID2.CONTIG\n",
    "GGC...\n",
    "...\n",
    "```\n",
    "\n",
    "nesta primeira sessão fazermos um parse desses arquivos para agrupar as sequẽncias por ID, calcular os kmers para esses contigs e obter um map com as freqências dos kmers em todos os contigs de uma sequẽncia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta_id_line(l):\n",
    "    \"\"\"\n",
    "    Desejamos extrair os IDs das sequências da linhas que começarem pelo caracter ''>'. Pelo padrão\n",
    "    FASTA, o ID é a primeira palavra e é um campo composto por ID.CONTIG\n",
    "    \n",
    "    Input>\n",
    "        l: Uma linha de um arquivo FASTA\n",
    "    Return:\n",
    "        ID: da sequência ignorando o número de contigs, ou None caso não seja uma linha de ID\n",
    "    \"\"\"\n",
    "    if l[0][0] == \">\":\n",
    "        heaer_splits = l[0][1:].split(\" \")[0]\n",
    "        seq_id_split = heaer_splits.split(\".\")\n",
    "        return seq_id_split[0]\n",
    "    else:\n",
    "        return None\n",
    "seq2kmer_udf = udf(parse_fasta_id_line, T.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_null_ids_df = fasta_plain_df.withColumn(\"seqID_wNull\", seq2kmer_udf(\"row\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecionar o resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+------------+\n",
      "|                 row|idx| seqID_wNull|\n",
      "+--------------------+---+------------+\n",
      "|[>QCWF01000001.1 ...|  0|QCWF01000001|\n",
      "|[TTTTTTTGTGTCTAGA...|  1|        null|\n",
      "|[TCACCGCGTGATCAGG...|  2|        null|\n",
      "|[AGATCCTGGTTTCACA...|  3|        null|\n",
      "|[ACCGATTCATCGCCCA...|  4|        null|\n",
      "|[AAAAGCCCGGTCACTG...|  5|        null|\n",
      "|[AGCTGAATCCTTGCGG...|  6|        null|\n",
      "|[AGAGGAACTCTTCGGC...|  7|        null|\n",
      "|[TAGCCCTCGTCGACCA...|  8|        null|\n",
      "|[TTCCTTGAGCATGATC...|  9|        null|\n",
      "|[TCAGGAACTCTGGGCG...| 10|        null|\n",
      "|[TCGCCGCCAGAGAACT...| 11|        null|\n",
      "|[CAGTGTGTTCTTGAAG...| 12|        null|\n",
      "|[ACACATCGGGGTGTGC...| 13|        null|\n",
      "|[CCGCCTTCGTTGAAGC...| 14|        null|\n",
      "|[GTCCAGGCGGATCATC...| 15|        null|\n",
      "|[TTGGGCCGGAGAAGAT...| 16|        null|\n",
      "|[ACCGCCTTGACGGCTT...| 17|        null|\n",
      "|[CTCGGTGAGCTTCTGA...| 18|        null|\n",
      "|[TCTCACTCACAGCAGC...| 19|        null|\n",
      "+--------------------+---+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_null_ids_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de seuências para serem processadas 10114\n"
     ]
    }
   ],
   "source": [
    "num_ids = fasta_null_ids_df.where(F.col(\"seqID_wNull\").isNotNull()).count()\n",
    "print(\"número de seuências para serem processadas\", num_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "desejamos fazer um \"fillna\" com o último valor não nulo encontrado na coluna de sequência, para isso usaremos um operador de janela deslizante em cima do índice que serve para manter a ordem original das linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_n_filter_df = fasta_null_ids_df.withColumn(\n",
    "    \"seqID\", F.last('seqID_wNull', ignorenulls=True)\\\n",
    "    .over(Window\\\n",
    "    .orderBy('idx')\\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir devemos excluir as linhas de header e renomear as colunas excluíndo as que não foram utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_df = fasta_n_filter_df\\\n",
    "                .where(F.col(\"seqID_wNull\").isNull())\\\n",
    "                .select(\"seqID\",\"row\")\\\n",
    "                .toDF(\"seqID\",\"seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Dataframe tratado tem o seguinte esquema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seqID: string (nullable = true)\n",
      " |-- seq: struct (nullable = true)\n",
      " |    |-- row: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspeção do daframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|       seqID|                 seq|\n",
      "+------------+--------------------+\n",
      "|QCWF01000001|[TTTTTTTGTGTCTAGA...|\n",
      "|QCWF01000001|[TCACCGCGTGATCAGG...|\n",
      "|QCWF01000001|[AGATCCTGGTTTCACA...|\n",
      "|QCWF01000001|[ACCGATTCATCGCCCA...|\n",
      "|QCWF01000001|[AAAAGCCCGGTCACTG...|\n",
      "|QCWF01000001|[AGCTGAATCCTTGCGG...|\n",
      "|QCWF01000001|[AGAGGAACTCTTCGGC...|\n",
      "|QCWF01000001|[TAGCCCTCGTCGACCA...|\n",
      "|QCWF01000001|[TTCCTTGAGCATGATC...|\n",
      "|QCWF01000001|[TCAGGAACTCTGGGCG...|\n",
      "|QCWF01000001|[TCGCCGCCAGAGAACT...|\n",
      "|QCWF01000001|[CAGTGTGTTCTTGAAG...|\n",
      "|QCWF01000001|[ACACATCGGGGTGTGC...|\n",
      "|QCWF01000001|[CCGCCTTCGTTGAAGC...|\n",
      "|QCWF01000001|[GTCCAGGCGGATCATC...|\n",
      "|QCWF01000001|[TTGGGCCGGAGAAGAT...|\n",
      "|QCWF01000001|[ACCGCCTTGACGGCTT...|\n",
      "|QCWF01000001|[CTCGGTGAGCTTCTGA...|\n",
      "|QCWF01000001|[TCTCACTCACAGCAGC...|\n",
      "|QCWF01000001|[TTCTCCTCGTTGCGGT...|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Kmers\n",
    "\n",
    "Nesta sessão faremos o cálculo dos [kmers](https://en.wikipedia.org/wiki/K-mer) de tambo ```K```. O objetivo é associar cada ID de sequência ao conjunto de kmers distiontos presentes em todos os seus motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq2kmerTy = T.ArrayType(T.StringType())\n",
    "def seq2kmer(seq_):\n",
    "    global K\n",
    "    value = seq_[0].strip()\n",
    "    num_kmers = len(value) - K + 1\n",
    "    kmers_list = [value[n*K:K*(n+1)] for n in range(0, num_kmers)]\n",
    "    \n",
    "    # return len(value)\n",
    "    return kmers_list\n",
    "\n",
    "seq2kmer_udf = udf(seq2kmer,Seq2kmerTy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_kmers_df = fasta_df\\\n",
    "        .withColumn(\"kmers\", seq2kmer_udf(\"seq\"))\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspeção do daframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seqID: string (nullable = true)\n",
      " |-- seq: struct (nullable = true)\n",
      " |    |-- row: string (nullable = true)\n",
      " |-- kmers: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_kmers_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+\n",
      "|       seqID|                 seq|               kmers|\n",
      "+------------+--------------------+--------------------+\n",
      "|ALPH01000001|[TCTCCCAGCACTTAGG...|[TCT, CCC, AGC, A...|\n",
      "|ALPH01000001|[CAACCTCTTTAGAGTT...|[CAA, CCT, CTT, T...|\n",
      "|ALPH01000001|[ATATTAGAAAGTACTT...|[ATA, TTA, GAA, A...|\n",
      "|ALPH01000001|[AATTCCCGCACTTCTT...|[AAT, TCC, CGC, A...|\n",
      "|ALPH01000001|[CAGGACTTGTATCAAG...|[CAG, GAC, TTG, T...|\n",
      "|ALPH01000001|[CCTGCAGTAACACATG...|[CCT, GCA, GTA, A...|\n",
      "|ALPH01000001|[TCTTATTTCTCTCCAA...|[TCT, TAT, TTC, T...|\n",
      "|ALPH01000001|[ATTCTACTTCTTGAAT...|[ATT, CTA, CTT, C...|\n",
      "|ALPH01000001|[CAACCTCCTGTTTTTA...|[CAA, CCT, CCT, G...|\n",
      "|ALPH01000001|[CCACATTAAATCTATA...|[CCA, CAT, TAA, A...|\n",
      "|ALPH01000001|[AATCTTGATTCAATTT...|[AAT, CTT, GAT, T...|\n",
      "|ALPH01000001|[CCACCAAATCTCCTAT...|[CCA, CCA, AAT, C...|\n",
      "|ALPH01000001|[ATCCGTTATATAAATT...|[ATC, CGT, TAT, A...|\n",
      "|ALPH01000001|[GCAAGTCAGGATCTTG...|[GCA, AGT, CAG, G...|\n",
      "|ALPH01000001|[CCTGAGATTGACTTCC...|[CCT, GAG, ATT, G...|\n",
      "|ALPH01000001|[TGTAAATTGATCATTA...|[TGT, AAA, TTG, A...|\n",
      "|ALPH01000001|[CGCCAATAAATTTGAT...|[CGC, CAA, TAA, A...|\n",
      "|ALPH01000001|[AGAAATTTCACCTCTT...|[AGA, AAT, TTC, A...|\n",
      "|ALPH01000001|[TTTAGAAACTTTAATT...|[TTT, AGA, AAC, T...|\n",
      "|ALPH01000001|[CCCATCTTCCATTACC...|[CCC, ATC, TTC, C...|\n",
      "+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasta_kmers_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validação, podemos obter estatísticas básicas dso kmers obtidos. Para isso vamos contar o número de kmers por ID de sequência e obter um describe da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kmers_df = fasta_kmers_df\\\n",
    "                    .withColumn(\"n_kmers\", size(col(\"kmers\")))\\\n",
    "                    .select(\"n_kmers\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|          n_kmers|\n",
      "+-------+-----------------+\n",
      "|  count|            84379|\n",
      "|   mean|77.11937804430012|\n",
      "| stddev|6.794605271811715|\n",
      "|    min|                0|\n",
      "|    max|               78|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_kmers_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise das Sequências \n",
    "\n",
    "A seguir analisaremos as sequẽncias a partir dos kmers obtidos. O profile de uma seuquência é um mapeamento ```kmer->num ocorrencias``` que pode ser utilizado em análises de similaridade entre sequências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "KmerFreqTuple = T.MapType(T.StringType(), T.IntegerType())\n",
    "\n",
    "def kmers_list2kmers_freq_dict(kmers_list):\n",
    "    \"\"\"\n",
    "    Cálcula as frequências absolutas de cda kmer no dataframe\n",
    "    Retorna:\n",
    "        Um onjeto map(\"kmer\" -> número de ocorrências ) para cada sequência\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(kmers_list[0], return_counts=True)\n",
    "    kmers_map = {str(k):int(v) for k, v in zip(unique, counts) if k}\n",
    "    return kmers_map\n",
    "\n",
    "kmers_list2kmers_freq_dict_udf = udf(kmers_list2kmers_freq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> esse dataframe foi criado apenas para inspeção, como utilizaremos o VectorCounter para criar features, o map em si tornou-se desnecessário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.86 ms, sys: 5.86 ms, total: 10.7 ms\n",
      "Wall time: 34.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmers_pofile_df = fasta_kmers_df\\\n",
    "            .groupby(\"seqID\")\\\n",
    "            .agg(F.collect_list('kmers').alias('kmers_list'))\\\n",
    "            .withColumn('kmers_freq', kmers_list2kmers_freq_dict_udf('kmers_list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|       seqID|          kmers_freq|\n",
      "+------------+--------------------+\n",
      "|ALPC01000098|{TGT=1, AA=1, AAA...|\n",
      "|ALPG01000168|{TTA=1, TT=1, TGT...|\n",
      "|ALPH01000049|{TTA=1, TT=1, ATT...|\n",
      "|ALPH01000154|{ATT=3, AAA=1, TT...|\n",
      "|ALPI01000077|{TTA=1, CCA=1, AA...|\n",
      "|ALPJ01000168|{TGT=1, GGA=1, AG...|\n",
      "|ALPK01000207|{TT=1, ATT=2, CGG...|\n",
      "|ALPD01000057|{TTA=2, GGA=1, AT...|\n",
      "|ALPH01000006|{GGA=1, CCA=2, CC...|\n",
      "|ALPH01000151|{TTA=1, ATT=1, TC...|\n",
      "|ALPH01000275|{TGT=1, ATT=1, AC...|\n",
      "|ALPI01000038|{TTA=1, TGT=1, GG...|\n",
      "|ALPJ01000066|{TTA=1, AGG=2, AA...|\n",
      "|ALPJ01000133|{TTA=2, TT=1, ATT...|\n",
      "|ALPJ01000183|{CCA=1, ATT=1, AC...|\n",
      "|ALPK01000019|{TTA=1, TT=1, GGA...|\n",
      "|ALPK01000076|{TTA=2, ATT=2, AA...|\n",
      "|ALPK01000121|{TTA=1, TGT=1, GG...|\n",
      "|ALPC01000044|{CCA=2, ATT=1, AA...|\n",
      "|ALPC01000071|{TTA=2, AGG=1, CC...|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmers_pofile_df.select(\"seqID\", \"kmers_freq\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extração de features\n",
    "\n",
    "O número de K que defie o tamanho dos k-mers define um espaço de features de dimensão $4^K$, para codificar essas features podemos usar a classe ```CountVectorizer```. Essa codificação atribui ordinais a cada kmer único e cria duas listas para representar a presença e o frequência absoluta dos mesmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmers_df = fasta_kmers_df.select(\"seqID\", \"kmers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.1 ms, sys: 5.86 ms, total: 37 ms\n",
      "Wall time: 6.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmers_pofile_df = fasta_kmers_df.rdd\\\n",
    "            .map(lambda r: (r.seqID, r.kmers))\\\n",
    "            .reduceByKey(lambda x,y: x+y)\\\n",
    "            .toDF([\"seqID\", \"kmers_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- seqID: string (nullable = true)\n",
      " |-- kmers_list: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmers_pofile_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|       seqID|          kmers_list|\n",
      "+------------+--------------------+\n",
      "|ALPH01000001|[TCT, CCC, AGC, A...|\n",
      "|ALPH01000002|[CCT, TGC, TTA, T...|\n",
      "|ALPH01000003|[ATT, CTT, CTT, C...|\n",
      "|ALPH01000004|[AAT, ATC, ATT, T...|\n",
      "|ALPH01000005|[AAC, TTT, TAA, T...|\n",
      "|ALPH01000006|[CCA, CTA, CTA, A...|\n",
      "|ALPH01000007|[CTT, GGC, TTG, T...|\n",
      "|ALPH01000008|[CTG, AGT, CCT, A...|\n",
      "|ALPH01000009|[CGA, TGT, AAT, G...|\n",
      "|ALPH01000010|[TCT, CAC, TAG, A...|\n",
      "|ALPH01000011|[GTT, TTT, ATC, A...|\n",
      "|ALPH01000012|[AGG, GTG, TCG, G...|\n",
      "|ALPH01000013|[TTT, TCA, TCT, A...|\n",
      "|ALPH01000014|[AAT, GTT, GTG, A...|\n",
      "|ALPH01000015|[ACT, GCA, GCA, T...|\n",
      "|ALPH01000016|[GCA, ATA, CCT, C...|\n",
      "|ALPH01000017|[GAC, TCT, GAA, A...|\n",
      "|ALPH01000018|[AGA, CTC, ATT, G...|\n",
      "|ALPH01000019|[CTT, CTA, TAT, C...|\n",
      "|ALPH01000020|[AGG, ATT, TTT, T...|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmers_pofile_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.12 ms, sys: 11.9 ms, total: 19 ms\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(inputCol=\"kmers_list\", outputCol=\"features\")\n",
    "\n",
    "model = cv.fit(kmers_pofile_df)\n",
    "\n",
    "features_df = model.transform(kmers_pofile_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+\n",
      "|       seqID|          kmers_list|            features|\n",
      "+------------+--------------------+--------------------+\n",
      "|ALPH01000001|[TCT, CCC, AGC, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000002|[CCT, TGC, TTA, T...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000003|[ATT, CTT, CTT, C...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000004|[AAT, ATC, ATT, T...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000005|[AAC, TTT, TAA, T...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000006|[CCA, CTA, CTA, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000007|[CTT, GGC, TTG, T...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000008|[CTG, AGT, CCT, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000009|[CGA, TGT, AAT, G...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000010|[TCT, CAC, TAG, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000011|[GTT, TTT, ATC, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000012|[AGG, GTG, TCG, G...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000013|[TTT, TCA, TCT, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000014|[AAT, GTT, GTG, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000015|[ACT, GCA, GCA, T...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000016|[GCA, ATA, CCT, C...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000017|[GAC, TCT, GAA, A...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000018|[AGA, CTC, ATT, G...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000019|[CTT, CTA, TAT, C...|(93,[0,1,2,3,4,5,...|\n",
      "|ALPH01000020|[AGG, ATT, TTT, T...|(93,[0,1,2,3,4,5,...|\n",
      "+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features únicas  1864\n",
      "CPU times: user 21.5 ms, sys: 3.89 ms, total: 25.4 ms\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unique_features_count = features_df.select(\"features\").distinct().count()\n",
    "print(\"Número de features únicas \",unique_features_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1864 das 1864 sequências tem features únicas\n"
     ]
    }
   ],
   "source": [
    "print(\"%d das %d sequências tem features únicas\" % (unique_features_count, num_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Para o ajuste dos hiperparâmetros da clusterização devemos fazer um parameter sweep para achar o número ideal de clusters. A avaliação da qualidade do cluster é dada pela [Métreica de Silhouette](https://spark.apache.org/docs/2.3.1/api/java/org/apache/spark/ml/evaluation/ClusteringEvaluator.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkm = BisectingKMeans()\n",
    "# model = bkm.fit(features_df)\n",
    "clustering_pipeline = Pipeline(stages=[bkm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.54 s, sys: 665 ms, total: 2.21 s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(bkm.k, [2, 5, 10, 20, 50, 70, 100]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=clustering_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=ClusteringEvaluator(),\n",
    "                          numFolds=5)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "cvModel= crossval.fit(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = cvModel.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+----------+\n",
      "|       seqID|          kmers_list|            features|prediction|\n",
      "+------------+--------------------+--------------------+----------+\n",
      "|ALPH01000001|[TCT, CCC, AGC, A...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000002|[CCT, TGC, TTA, T...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000003|[ATT, CTT, CTT, C...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000004|[AAT, ATC, ATT, T...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000005|[AAC, TTT, TAA, T...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000006|[CCA, CTA, CTA, A...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000007|[CTT, GGC, TTG, T...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000008|[CTG, AGT, CCT, A...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000009|[CGA, TGT, AAT, G...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000010|[TCT, CAC, TAG, A...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000011|[GTT, TTT, ATC, A...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000012|[AGG, GTG, TCG, G...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000013|[TTT, TCA, TCT, A...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000014|[AAT, GTT, GTG, A...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000015|[ACT, GCA, GCA, T...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000016|[GCA, ATA, CCT, C...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000017|[GAC, TCT, GAA, A...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000018|[AGA, CTC, ATT, G...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000019|[CTT, CTA, TAT, C...|(93,[0,1,2,3,4,5,...|         0|\n",
      "|ALPH01000020|[AGG, ATT, TTT, T...|(93,[0,1,2,3,4,5,...|         0|\n",
      "+------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|          prediction|\n",
      "+-------+--------------------+\n",
      "|  count|                1864|\n",
      "|   mean|0.032188841201716736|\n",
      "| stddev|  0.1765486944363821|\n",
      "|    min|                   0|\n",
      "|    max|                   1|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_df.select(\"prediction\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark]",
   "language": "python",
   "name": "conda-env-pyspark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
